{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcc12858",
   "metadata": {},
   "source": [
    "## **Go Tesseract**\n",
    "\n",
    "`tesseract` : Version `4.1.1`\n",
    "\n",
    "`languages` : `eng`, `nep`\n",
    "\n",
    "We're using `WSL` to run Tesseract OCR with Go. Below are the steps to set up and use Tesseract OCR in a `Go` project.\n",
    "\n",
    "**Go Version**: `1.18`\n",
    "\n",
    "**GoTesseract Docs**\n",
    "\n",
    "[Docs](https://pkg.go.dev/github.com/otiai10/gosseract#section-readme)\n",
    "\n",
    "**GoTesseract GitHub Repository**\n",
    "\n",
    "[GitHub Repo](https://github.com/otiai10/gosseract)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91f66a8",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<hr>\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d227846d",
   "metadata": {},
   "source": [
    "## **Task**\n",
    "\n",
    "### **Images Types**\n",
    "\n",
    "**Machine PDF**\n",
    "\n",
    "**Machine But Scanned**\n",
    "\n",
    "**Scanned But Low Quality**\n",
    "\n",
    "**Handwritten**\n",
    "\n",
    "**Handwritten Bad Quality**\n",
    "\n",
    "For each image, run the analysis and document the results below.\n",
    "\n",
    "### **Prepare Report**\n",
    "\n",
    "- Some words are missplelled. We've to post process the `Misspelled Words` using `Dictionary` or `Language Model`.\n",
    "\n",
    "**Average Confidence** : Take the confidence of each word and calculate the average confidence of the entire text.\n",
    "\n",
    "**Identify Common Pitfalls** : Identify common pitfalls or errors that Tesseract makes with each type of image.\n",
    "\n",
    "<hr>\n",
    "\n",
    "## **Results**\n",
    "\n",
    "### **Handwritten**\n",
    "\n",
    "`Handwritten_Clean.png` : 20.7698\n",
    "\n",
    "`Handwritten_Noise.png` : 26.9336\n",
    "\n",
    "**Average Confidence** : 23.8517\n",
    "\n",
    "On handwritten images, Tesseract does not perform well. \n",
    "\n",
    "Because `Tesseract` was trained on `Fonts` not `Handwriting`. Handwriting varies significantly from person to person, making it difficult for Tesseract to accurately recognize characters.\n",
    "\n",
    "The `nep.traineddata` file we're using was trained on `Synthetic Data` and `Printed Text`, not on `Handwritten Text`.\n",
    "\n",
    "Also, it expects `Clear` white spaces around the characters, which is often not the case in handwritten notes.\n",
    "\n",
    "**Solutions**\n",
    "\n",
    "- Train a custom model using `Tesseract` with a dataset of handwritten text samples.\n",
    "\n",
    "- Use `Deep Learning` based OCR models like `EasyOCR` or `Google Vision API` that are better at handling handwriting.\n",
    "\n",
    "- `Azure Computer Vision API` also provides good results for handwritten text recognition.\n",
    "\n",
    "- `Google Cloud Vision API` has a dedicated feature for recognizing handwritten text.\n",
    "\n",
    "- `RAG` pipeline to extract the text and get the output in a better format.\n",
    "\n",
    "- `trOCR_ne` or `trOCR` models from `HuggingFace` [Link_Ne](https://huggingface.co/rockerritesh/trOCR_ne)\n",
    "\n",
    "<hr>\n",
    "<hr>\n",
    "\n",
    "### **Machine PDF**\n",
    "\n",
    "`img-2.png` : 93.3134\n",
    "`img-3.png` : 90.1242\n",
    "\n",
    "**Average Confidence** : 91.7188\n",
    "\n",
    "For `Machine PDFs`, Tesseract performs very well. The text is clear and well-defined, allowing Tesseract to accurately recognize characters.\n",
    "\n",
    "There are not many common pitfalls with machine-generated PDFs, as the text is typically in a standard font and format.\n",
    "\n",
    "As the model is trained on printed text, it can easily recognize the characters in machine PDFs.\n",
    "\n",
    "<hr>\n",
    "<hr>\n",
    "\n",
    "### **Machine But Scanned**\n",
    "\n",
    "`bar-06.png` : 66.7277\n",
    "\n",
    "`bar-09.png` : 69.5565\n",
    "\n",
    "**Average Confidence** : 68.1421\n",
    "\n",
    "For `Scanned Machine PDFs`, Tesseract performs moderately well. The quality of the scan can affect the accuracy of text recognition.\n",
    "\n",
    "Common pitfalls include:\n",
    "\n",
    "- Blurriness or low resolution of the scanned image can lead to misrecognition of characters.\n",
    "\n",
    "- Skewed or rotated text can also pose challenges for Tesseract.\n",
    "\n",
    "- Due to noise in the scanned image, some characters may be misinterpreted. We need to `Post Process` the output to fix these errors.\n",
    "\n",
    "<hr>\n",
    "<hr>\n",
    "\n",
    "### **Scanned But Low Quality**\n",
    "\n",
    "Completely Scanned i.e. `Black and White` images with `Low Resolution` and `Noise`.\n",
    "\n",
    "`Scanned.png` : 71.6776\n",
    "\n",
    "**Average Confidence** : 71.6776\n",
    "\n",
    "Works decently well. But there are some mispellings. We can post process the output to fix these errors.\n",
    "\n",
    "<hr>\n",
    "<hr>\n",
    "\n",
    "### **`RAG` Solution for Overall High Score**\n",
    "\n",
    "Use `RAG` pipeline to extract text from images. \n",
    "\n",
    "We can use `AiStudio` `API` to build a `RAG` pipeline to provide the `Image` as input and get the `Text` as output.\n",
    "\n",
    "It works really well for all types of images. Especially for `Handwritten` images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779860ab",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<hr>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7d7d10",
   "metadata": {},
   "source": [
    "# **Working of Tesseract**\n",
    "\n",
    "Before Tesseract reads a single letter, it must understand the \"geometry\" of the page. This is handled by a library called `Leptonica` and Tesseract's internal layout engine.\n",
    "\n",
    "Modern `Tesseract` OCR engine is i.e. `V4` or `V5` combines `Old School Computer Vision` techniques with `LSTM` based `Deep Learning` models.\n",
    "\n",
    "## **Phase 1:**\n",
    "\n",
    "### **Adaptive Thresholding / Binarization**\n",
    "\n",
    "First, the image is pre-processed using various techniques like `Binarization`, `Noise Removal`, `Skew Correction`, etc. to enhance the quality of the image for better text recognition.\n",
    "\n",
    "Tesseract does not read color or grayscale images directly. It converts everything to Binary (Black and White).\n",
    "\n",
    "**How it works:**\n",
    "\n",
    "It doesn't just say \"Anything darker than 50% is black.\" It uses `Local Adaptive Thresholding`. It looks at a small window of pixels. If a pixel is significantly darker than its neighbors, it becomes black (text).\n",
    "\n",
    "### **Connected Component Analysis (Blob Finding)**\n",
    "\n",
    "Once the image is `Binarized`, Tesseract looks for groups of connected black pixels called `Blobs`. Each blob could be a part of a letter, a whole letter, or even multiple letters stuck together.\n",
    "\n",
    "- A `Blob` is a group of connected pixels that are all the same color (in this case, black).\n",
    "\n",
    "- In `English`, the letter `i` might be split into two blobs: the dot and the stem. In `Devanagari`, the `Top Line (Shirorekha)` connects multiple letters into a single blob.\n",
    "\n",
    "### **Page Layout Analysis (PLA)**\n",
    "\n",
    "This is the most complex non-AI part. Tesseract tries to find the structure.\n",
    "\n",
    "- `Tab Stop Detection`: It looks for vertical alignments of text to identify columns and tables.\n",
    "\n",
    "- `Gutter Detection`: It looks for `Horizontal Spaces` between blocks of text to separate paragraphs.\n",
    "\n",
    "`Tesseract` has hard-coded thresholds for how much white space constitutes a `Pagaraph Break` or a `Column Break`. So if `Nepali` text has a large font size or smaller line height, it might misinterpret the layout.\n",
    "\n",
    "In such cases, we've to manually calculate the `Gaps` and set the `Page Segmentation Mode (PSM)` accordingly.\n",
    "\n",
    "\n",
    "### **Line Finding and Baseline Estimation**\n",
    "\n",
    "`Tesseract` groups blobs into lines of text. It estimates the `Baseline` for each line, which is the imaginary line on which most letters sit.\n",
    "\n",
    "- It fits Mathematical Curve `Spline` to the bottom of the blobs in a line to estimate the baseline.\n",
    "\n",
    "- This helps in recognizing letters that have parts going below the baseline, like `g`, `j`, `p` in English or `ज`, `घ`, `फ` in Nepali.\n",
    "\n",
    "## **Phase 2: Recognizing Characters with LSTM**\n",
    "\n",
    "Once `Tesseract` has identified lines of text and their baselines i.e. `Image Segmentation` for that line, it moves to the `LSTM` based recognition phase.\n",
    "\n",
    "### **Sliding Window Approach**\n",
    "\n",
    "Tesseract uses a `Sliding Window` approach to recognize characters. It takes small vertical slices of the line image and feeds them into the `LSTM` network.\n",
    "\n",
    "- Each slice is typically a few pixels wide and spans the full height of the line.\n",
    "\n",
    "- The `LSTM` processes these slices sequentially, maintaining a memory of previous slices to understand context.\n",
    "\n",
    "### **The Probability Output**\n",
    "\n",
    "For each slice, the `LSTM` outputs a probability distribution over all possible characters (including a special \"blank\" character).\n",
    "\n",
    "- `Slice 1`: 70% 'H', 20% 'A', 10% 'Blank'\n",
    "\n",
    "- `Slice 2`: 40% chance it's 'क', 30% chance it's 'ब'.\n",
    "  \n",
    "- `Slice 3`: 80% chance it's 'क'.\n",
    "\n",
    "### **CTC Decoding (Connectionist Temporal Classification)**\n",
    "\n",
    "The raw output is a messy streams like `H H A _ _ क क ब क _ _` \n",
    "\n",
    "where `_` represents the blank character.\n",
    "\n",
    "The `CTC` algorithm cleans this up by removing duplicates and blanks, resulting in the final recognized text.\n",
    "\n",
    "- Repeated characters are merged: `H H A` becomes `H A`.\n",
    "\n",
    "- It collapses blanks: `H A _ _` becomes `H A`.\n",
    "\n",
    "### **Confidence Scoring**\n",
    "\n",
    "Tesseract assigns a confidence score to each recognized character and the overall line based on the probabilities output by the `LSTM`.\n",
    "\n",
    "- Higher confidence scores indicate more reliable recognition.\n",
    "\n",
    "## **Phase 3: Post-Processing**\n",
    "\n",
    "After the `Neural Network` has recognized the text, Tesseract performs several post-processing steps to improve accuracy.\n",
    "\n",
    "`Tesseract` checks its work using the `Language Data Files` (`.traineddata` files) that contain dictionaries and language models.\n",
    "\n",
    "### **Dictionary Lookup**\n",
    "\n",
    "Tesseract compares recognized words against its internal dictionaries to correct common OCR errors.\n",
    "\n",
    "- `Tesseract` uses a `Directed Acyclic Word Graph (DAWG)` to efficiently store and look up words. It checks if the word `तपाईं` exists in the Nepali dictionary.\n",
    "\n",
    "- If the `LSTM` was 51% sure it saw `तपाईं` and 49% sure it saw `तपाई`, Tesseract will correct it to `तपाईं` based on the dictionary.\n",
    "\n",
    "### **N-Grams and Bigrams**\n",
    "\n",
    "It looks at word pairs. If `नेपाल सरकार` is a common bigram in Nepali, and the OCR output is `नेपाल ससरकार`, Tesseract might correct it to `नेपाल सरकार`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8af5c28",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<hr>\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c450b10",
   "metadata": {},
   "source": [
    "## **Task**\n",
    "\n",
    "**Dockerize the `GoTesseract` Application**\n",
    "\n",
    "**`Gofiber` as an HTTP Server to handle Image Uploads and return Extracted Text**\n",
    "\n",
    "- Implement `JWT` rate limiting everything as a side project"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
